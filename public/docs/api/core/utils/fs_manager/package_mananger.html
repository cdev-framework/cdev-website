<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>core.utils.fs_manager.package_mananger API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em;background:#EEE}#content{padding:20px}#sidebar{padding:30px;overflow:hidden;background:#07085d}#sidebar > *:last-child{margin-bottom:2cm}#sidebar::-webkit-scrollbar{width:8px}#sidebar::-webkit-scrollbar-track{border-radius:10px;background:#f1f1f100}#sidebar::-webkit-scrollbar-thumb{border-radius:10px;background:linear-gradient( 37deg,rgb(247,70,58) 1%,rgb(180,62,121) 80% )}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}a.sidebar{color:white;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#f7463a}a.nav-header{color:white}img.logo-img{display:block;margin-left:auto;margin-right:auto;width:25%}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#e0e0e0;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{height:100vh;overflow:auto;position:sticky;top:0;background:#07085d}#content{width:70%;max-width:200ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<!--<link rel="stylesheet"
href='https://cdevwebsitestaging.s3.amazonaws.com/bootstrap/css/bootstrap.min.css'>-->
<script href='/bootstrap/css/bootstrap.js'></script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>core.utils.fs_manager.package_mananger</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
from pathlib import Path
import pkg_resources
from pydantic.types import DirectoryPath, FilePath
import re
from sortedcontainers.sorteddict import SortedDict
import sys
from typing import List, Set, Dict, Tuple, Union, Optional

from serverless_parser import parser as cdev_parser

from . import docker_package_builder
from .utils import PackageTypes, ModulePackagingInfo, lambda_python_environments

# Keep cache of already seen package names
PACKAGE_CACHE = {}

# There isn&#39;t a great runtime way of identifying python standard libraries (non C builtin libraries packaged with python).
# So I scraped the information from the python documentation website using the ./scripts/list-python-builtins
STANDARD_LIBRARY_FILES = [&#34;3_6&#34;, &#34;3_7&#34;, &#34;3_8&#34;]

# Build a dict of pkg name to pip package obj so you don&#39;t have to loop over all the packages when doing a look up
# We need to include both a the project name and &#39;toplevel&#39; name. This is because a project can have a python unsafe name
# so it is allowed to have a different name that is used when importing the package in an actual python file. Both need to
# be include because, when the package is reference directly in a file it will have the top name, but when it is referenced
# as the dependency of another project it will be a the project name.
MOD_NAME_TO_PRJ_OBJ: Dict[str, pkg_resources.Distribution] = {}

PRJ_NAME_TO_TOP_LEVEL_MODULES: Dict[str, List[str]] = {}


DEPLOYMENT_PLATFORM = &#34;arm64&#34;

INCOMPATIBLE_PROJECTS = set()

_already_checked_cache = set()


def _is_platform_compatible(tags: List[str]) -&gt; bool:
    # https://packaging.python.org/specifications/platform-compatibility-tags/
    # PEP 600
    LEGACY_ALIASES = {
        &#34;manylinux1_x86_64&#34;: &#34;manylinux_2_5_x86_64&#34;,
        &#34;manylinux1_i686&#34;: &#34;manylinux_2_5_i686&#34;,
        &#34;manylinux2010_x86_64&#34;: &#34;manylinux_2_12_x86_64&#34;,
        &#34;manylinux2010_i686&#34;: &#34;manylinux_2_12_i686&#34;,
        &#34;manylinux2014_x86_64&#34;: &#34;manylinux_2_17_x86_64&#34;,
        &#34;manylinux2014_i686&#34;: &#34;manylinux_2_17_i686&#34;,
        &#34;manylinux2014_aarch64&#34;: &#34;manylinux_2_17_aarch64&#34;,
        &#34;manylinux2014_armv7l&#34;: &#34;manylinux_2_17_armv7l&#34;,
        &#34;manylinux2014_ppc64&#34;: &#34;manylinux_2_17_ppc64&#34;,
        &#34;manylinux2014_ppc64le&#34;: &#34;manylinux_2_17_ppc64le&#34;,
        &#34;manylinux2014_s390x&#34;: &#34;manylinux_2_17_s390x&#34;,
    }

    interpreter_tag = tags[0]
    platform_tag = tags[-1]

    if not (interpreter_tag[:2] == &#34;py&#34; or interpreter_tag[:2] == &#34;cp&#34;):
        # Not a cpython or generic python package
        raise Exception

    if platform_tag == &#34;any&#34;:
        return True

    if &#34;win32&#34; in platform_tag:
        return False

    elif &#34;macosx&#34; in platform_tag:
        return False

    else:
        # linux tag
        # Directly from PEP 600
        # Normalize and parse the tag
        tag = LEGACY_ALIASES.get(platform_tag, platform_tag)
        m = re.match(&#34;manylinux_([0-9]+)_([0-9]+)_(.*)&#34;, tag)
        if not m:
            return False
        tag_major_str, tag_minor_str, tag_arch = m.groups()
        tag_major = int(tag_major_str)
        tag_minor = int(tag_minor_str)

        if not tag_arch == DEPLOYMENT_PLATFORM:
            return False

        return True


for project_obj in pkg_resources.working_set:
    # We need to compute some information about the available modules in the current environment. This will help to provide information about
    # the modules when handlers reference them.

    # Compute:
    # MOD_NAME_TO_PRJ_OBJ -&gt; Dict from the module name to the project object that contains the metadata about the project the module is from
    # PRJ_NAME_TO_TOP_LEVEL_MODULES -&gt; Dict from the project name to all of its top level modules which are used when including the project as a dependency
    # INCOMPATIBLE_PROJECTS -&gt; Projects that are not platform agnostic and would therefore need to be redownloaded for the correct deployment architecture

    # For information on this object check
    # https://setuptools.pypa.io/en/latest/pkg_resources.html#distribution-objects
    # Distribution Object

    # find the dist info directory that will contain metadata about the package
    dist_dir_location = os.path.join(
        project_obj.location,
        f&#34;{project_obj.project_name.replace(&#39;-&#39;, &#39;_&#39;)}-{project_obj.parsed_version}.dist-info&#34;,
    )
    toplevel_file_location = os.path.join(dist_dir_location, &#34;top_level.txt&#34;)
    wheel_info = os.path.join(dist_dir_location, &#34;WHEEL&#34;)

    if not os.path.isdir(dist_dir_location):
        continue

    if not os.path.isfile(toplevel_file_location):
        # If not top level file is present, then assume the only top level module available is the project name
        MOD_NAME_TO_PRJ_OBJ[project_obj.project_name] = project_obj
        PRJ_NAME_TO_TOP_LEVEL_MODULES[project_obj.project_name] = [
            project_obj.project_name
        ]
        continue

    with open(toplevel_file_location) as fh:
        top_level_mod_names = fh.readlines()

        for top_level_mod_name in top_level_mod_names:
            MOD_NAME_TO_PRJ_OBJ[top_level_mod_name.strip()] = project_obj

        potential_modules = [x.strip() for x in top_level_mod_names]
        actual_modules = []
        for potential_module in potential_modules:
            # The module could be either a folder (normal case) or a single python file (ex: &#39;six&#39; package)
            # If it can not be found as either than there is an issue
            potential_dir = os.path.join(project_obj.location, potential_module)
            potential_file = os.path.join(
                project_obj.location, potential_module + &#34;.py&#34;
            )

            if not os.path.isdir(potential_dir) and not os.path.isfile(potential_file):
                # print(f&#34;Could not find module {potential_module} at {dist_dir_location}&#34;)
                continue

            actual_modules.append(potential_module)

        PRJ_NAME_TO_TOP_LEVEL_MODULES[project_obj.project_name] = actual_modules

    with open(wheel_info) as fh:
        lines = fh.readlines()

        # https://www.python.org/dev/peps/pep-0425/
        # if it is not pure it should only have one tag
        # We are going ot check the tags of the package to make sure it is compatible with the target deployment platform
        tags = (
            [x.split(&#34;:&#34;)[1] for x in lines if x.split(&#34;:&#34;)[0] == &#34;Tag&#34;][0]
            .strip()
            .split(&#34;-&#34;)
        )

        if not _is_platform_compatible(tags):
            INCOMPATIBLE_PROJECTS.add(project_obj.project_name)


def get_top_level_module_info(
    modules: List[str], start_location: FilePath
) -&gt; Dict[str, ModulePackagingInfo]:
    &#34;&#34;&#34;
    Create a sorted dictionary of all the module information needed for the used modules in a handler.

    Args:
        modules (List[str]): Module names used to by a handler
        start_location (Filepath): The location of the original file to help dereference relative modules

    Returns:
        module_infos (SortedDict[str, ModulePackagingInfo]): Dict (Sorted by module name) of the module information
        objects that will be used to package the module with the handler
    &#34;&#34;&#34;
    all_packages = {}

    _clear_already_checked_cache(start_location)

    for module_name in modules:
        all_packages[module_name] = _get_module_info(module_name, start_location)

    return SortedDict(all_packages)


def _get_module_info(
    module_name: str, original_file_location: str
) -&gt; ModulePackagingInfo:
    &#34;&#34;&#34;
    Create the information needed to package this dependency with a parsed function. We use the recursive method because
    we must compute the package information for the dependencies of this dependency. Returns a ModulePackagingInfo objects
    that represent the information to handle the packaging steps.

    Args:
        module_name (str): The module name to look up. It can also be a relative name (begins with &#39;.&#39;)
        original_file_location (str): Since the module name can be a relative import it needs to have the location of the
        starting location

    Returns
        info (ModulePackagingInfo): information for the packages to package

    &#34;&#34;&#34;

    # Note the the cache is implemented at the recursive level so that recursive calls can benefit from the cache also
    info = _recursive_create_module_package_info(module_name, original_file_location)

    return info


def _clear_already_checked_cache(starting_location: str):
    # Add the starting file of the recursive calls
    global _already_checked_cache

    _already_checked_cache = set()

    _already_checked_cache.add(starting_location)


def _recursive_create_module_package_info(
    module_name: str, original_file_location: str
) -&gt; ModulePackagingInfo:
    &#34;&#34;&#34;
    Recursively create a module information object by finding out what type of module this is, and then recursively creating
    any dependant modules.

    Args:
        module_name (str): This is the top level module name used by the handler (can be a relative module)
        original_file_location: Location to use as start point if a local module is given

    Returns:
        module_info (ModulePackagingInfo): Information object for the given module

    &#34;&#34;&#34;

    if (module_name, original_file_location) in PACKAGE_CACHE:
        # Look in the cache if there is already information about this module to speed up the process
        return PACKAGE_CACHE.get((module_name, original_file_location))

    if (
        not module_name in sys.modules
        and not module_name in MOD_NAME_TO_PRJ_OBJ
        and not module_name[0] == &#34;.&#34;
    ):
        # The module name is not in the available system modules and also not a relative module
        print(f&#34;BAD PKG NAME -&gt; {module_name}&#34;)
        raise Exception

    else:
        standard_lib_info = _load_standard_library_information(&#34;3_6&#34;)
        aws_packages = _load_aws_packages(&#34;3_6&#34;)
        pip_packages = _load_mod_to_prj()

        if module_name in standard_lib_info:
            # Module is from the standard library
            rv = ModulePackagingInfo(
                **{
                    &#34;module_name&#34;: module_name,
                    &#34;type&#34;: PackageTypes.STANDARDLIB,
                    &#34;version_id&#34;: None,
                    &#34;fp&#34;: None,
                }
            )

        elif module_name in aws_packages:
            # Module is part of the default libraries available in the aws lambda python environment
            rv = ModulePackagingInfo(
                **{
                    &#34;module_name&#34;: module_name,
                    &#34;type&#34;: PackageTypes.AWSINCLUDED,
                    &#34;version_id&#34;: None,
                    &#34;fp&#34;: None,
                }
            )

        elif module_name in pip_packages:
            # Module was installed with a package manager and therefor contains additional metadata that can be used to find the dependencies
            tmp_distribution_obj = pip_packages.get(module_name)

            project_name = tmp_distribution_obj.project_name

            if project_name in INCOMPATIBLE_PROJECTS:
                # Some of the projects that can be installed are platform dependant and the users environment might not match the aws lambda
                # environment. So, we need to use docker to pull the compatible version of the library then use that in the final archive

                # TODO: Make this derive from the settings
                pull_libraries = True
                if pull_libraries:
                    if docker_package_builder.docker_available():
                        # Not that the download package function uses a cache so it will only actually pull the first time the user wants to
                        # package this function.
                        rv = docker_package_builder.download_package_and_create_moduleinfo(
                            tmp_distribution_obj,
                            lambda_python_environments.py38_arm64,
                            module_name,
                        )
                        PACKAGE_CACHE[(module_name, original_file_location)] = rv
                        return rv

                    else:
                        raise Exception

                # TODO make this a wanring maybe
                raise Exception

            # The package could be either a folder (normal case) or a single python file (ex: &#39;six&#39; package)
            # If it can not be found as either than there is an issue
            potential_dir = os.path.join(
                pip_packages.get(module_name).location, module_name
            )
            potential_file = os.path.join(
                pip_packages.get(module_name).location, module_name + &#34;.py&#34;
            )

            if os.path.isdir(potential_dir):
                tmp_fp = potential_dir
            elif os.path.isfile(potential_file):
                tmp_fp = potential_file
            else:
                raise Exception

            # Find the dependent modules for this project (distribution obj)
            (
                tmp_dependencies_flat,
                tmp_dependencies_tree,
            ) = _recursive_check_for_dependencies_project(tmp_distribution_obj)

            rv = ModulePackagingInfo(
                **{
                    &#34;module_name&#34;: module_name,
                    &#34;type&#34;: PackageTypes.PIP,
                    &#34;version_id&#34;: tmp_distribution_obj.version,
                    &#34;fp&#34;: tmp_fp,
                    &#34;flat&#34;: tmp_dependencies_flat,
                    &#34;tree&#34;: tmp_dependencies_tree,
                }
            )

        else:
            mod = sys.modules.get(module_name)
            if mod:
                if not mod.__file__:
                    # if the module __file__ is not present than it is a builtin module to the interpreter
                    tmp_type = PackageTypes.BUILTIN
                    tmp_fp = None
                    tmp_version = None
                else:
                    # this is a local package that was not imported using a relative path
                    tmp_type = PackageTypes.LOCALPACKAGE
                    tmp_version = None

                    if mod.__file__.split(&#34;/&#34;)[-1] == &#34;__init__.py&#34;:
                        tmp_fp = os.path.dirname(mod.__file__)
                    else:
                        tmp_fp = mod.__file__
            elif module_name[0] == &#34;.&#34;:
                # IF the module name started with a &#39;.&#39; then it is a relative import
                # TODO Change this to a different type because it is important for the packaging step
                tmp_type = PackageTypes.LOCALPACKAGE
                tmp_version = None

                tmp_module_name = module_name

                levels = 0
                # loop to compute how many layers up this relative import is by popping off the &#39;.&#39; char
                # until it reaches a different char
                while tmp_module_name[0] == &#34;.&#34;:
                    tmp_module_name, next_char = tmp_module_name[1:], tmp_module_name[0]

                    if next_char == &#34;.&#34;:
                        levels = levels + 1
                    else:
                        break

                original_path = Path(original_file_location)

                # go up the amount of levels need to get to the top of the search path
                relative_base_dir = original_path.parents[levels - 1]

                # since we popped off the leading &#39;.&#39; chars, the remaining portion is the path to search down from the top
                tmp_pkg_path_parts = tmp_module_name.split(&#34;.&#34;)

                # Again the module can either be a single file or a directory containing other files
                tmp_potential_file = os.path.join(
                    relative_base_dir,
                    &#34;/&#34;.join(tmp_pkg_path_parts[:-1]),
                    tmp_pkg_path_parts[-1] + &#34;.py&#34;,
                )
                tmp_potential_dir = os.path.join(
                    relative_base_dir, &#34;/&#34;.join(tmp_pkg_path_parts)
                )

                if os.path.isfile(tmp_potential_file):
                    tmp_fp = tmp_potential_file
                elif os.path.isdir(tmp_potential_dir):
                    tmp_fp = tmp_potential_dir
                else:
                    raise Exception

            else:
                raise Exception

            # Since this is a local package, it does not contain any extra metadata. This means the only way to find the dependencies is to
            # parse each python file in the needed module and look at its imports :/
            (
                dependencies_flat,
                dependencies_tree,
            ) = _recursive_check_for_dependencies_package(tmp_fp)

            rv = ModulePackagingInfo(
                **{
                    &#34;module_name&#34;: module_name,
                    &#34;type&#34;: tmp_type,
                    &#34;version_id&#34;: tmp_version,
                    &#34;fp&#34;: tmp_fp,
                    &#34;flat&#34;: dependencies_flat,
                    &#34;tree&#34;: dependencies_tree,
                }
            )

        PACKAGE_CACHE[(module_name, original_file_location)] = rv
        return rv


def _recursive_check_for_dependencies_project(
    project_distribution_obj: pkg_resources.Distribution,
) -&gt; Tuple[List[ModulePackagingInfo], List[ModulePackagingInfo]]:
    &#34;&#34;&#34;
    Create the ModulePackagingInfo objects for all dependencies of this project. By calling the &#39;_recursive_create_module_package_info&#39; to create the
    ModulePackagingInfo objects, it creates a recursive stack that eventually leads to tmp_flat being a list of ALL needed dependencies and the tmp_tree
    to be the first level in the dependency tree for this project.

    Args:
        project_distribution_obj (pkg_resources.Distribution): object from pkg_resources that contains metadata on this package

    Returns:
        flat (List[ModulePackagingInfo]): List of ALL needed dependencies
        tree (List[ModulePackagingInfo]): First level of a dependency tree for this project
    &#34;&#34;&#34;
    tmp_flat = set()
    tmp_tree = set()

    for project_obj in project_distribution_obj.requires():

        if project_obj.project_name in PRJ_NAME_TO_TOP_LEVEL_MODULES:
            project_name = project_obj.project_name

        # Note that pip packages should list their dependencies as the project name, but some use the top level module name that
        # can be slightly different than the project name.
        # Example awswrangler (2.12.1) lists &#39;Requires-Dist: pymysql (&gt;=0.9.0,&lt;1.1.0)&#39; but the actual package name is &#39;PyMySQL&#39;
        # .....python packaging sucks
        elif project_obj.project_name in MOD_NAME_TO_PRJ_OBJ:
            project_name = MOD_NAME_TO_PRJ_OBJ.get(
                project_obj.project_name
            ).project_name
        else:
            raise Exception

        top_level_modules = PRJ_NAME_TO_TOP_LEVEL_MODULES.get(project_name)

        for req in top_level_modules:

            tmp_dep = _recursive_create_module_package_info(req, None)
            tmp_flat.add(tmp_dep)
            tmp_tree.add(tmp_dep)

            if tmp_dep.flat:
                tmp_flat = tmp_flat.union(set(tmp_dep.flat))

    return tmp_flat, tmp_tree


def _recursive_check_for_dependencies_package(
    fp: Union[FilePath, DirectoryPath]
) -&gt; Tuple[List[ModulePackagingInfo], List[ModulePackagingInfo]]:
    &#34;&#34;&#34;
    Create the ModulePackagingInfo objects for all dependencies of this local module. By calling the &#39;_recursive_create_module_package_info&#39; to create the
    ModulePackagingInfo objects, it creates a recursive stack that eventually leads to tmp_flat being a list of ALL needed dependencies and the tmp_tree
    to be the first level in the dependency tree for this project.

    Args:
        project_distribution_obj (pkg_resources.Distribution): object from pkg_resources that contains metadata on this package

    Returns:
        flat (List[ModulePackagingInfo]): List of ALL needed dependencies
        tree (List[ModulePackagingInfo]): First level of a dependency tree for this project
    &#34;&#34;&#34;
    tmp_flat = set()
    tmp_tree = set()

    required_items = _get_local_package_dependencies(fp)

    for req in required_items:
        starting_location = fp if not req[1] else req[1]

        tmp_dep = _recursive_create_module_package_info(req[0], starting_location)

        tmp_flat.add(tmp_dep)
        tmp_tree.add(tmp_dep)

        if tmp_dep.flat:
            tmp_flat = tmp_flat.union(set(tmp_dep.flat))

    return list(tmp_flat), tmp_tree


def _get_local_package_dependencies(
    fp: Union[FilePath, DirectoryPath]
) -&gt; List[Tuple[str, Optional[str]]]:
    &#34;&#34;&#34;
    Get the local dependencies for a given local module by searching through the file/s that make up the module and looking
    for import statements.

    Args:
        fp (Union[FilePath, DirectoryPath]): the location of the module in question

    Returns:
        dependencies (List[Tuple[str,str]]): List of dependant module names and an optional filepath if the module is a relative module
    &#34;&#34;&#34;

    #_current_working_dir = CDEV_SETTINGS.get(&#34;CURRENT_PARSING_DIR&#34;)
    # TODO: Make this a setting
    _current_working_dir = None

    if not _current_working_dir:
        # This setting should be set
        raise Exception

    # Since we are just reading the files not importing them. We do not have a guarantee to not cause a circular dependency
    # Therefore, we preload all the files we are going to check before checking them, and add that to a cache to check against
    # If a file is already in the cache, it means it has/or will be accounted for.

    if fp in _already_checked_cache:
        # We have already included this file so skip it
        return []

    # Local Module can be either directory or single file
    if os.path.isdir(fp):
        module_names = set()

        for dir, _, files in os.walk(fp):
            if dir in _already_checked_cache:
                continue

            # Load the directory (and subdirectories)
            _already_checked_cache.add(dir)

            for file in files:
                if not file[-3:] == &#34;.py&#34;:
                    continue

                # Load the files
                if os.path.join(dir, file) in _already_checked_cache:
                    continue

                _already_checked_cache.add(os.path.join(dir, file))

                module_names = module_names.union(
                    cdev_parser.parse_file_for_dependencies(os.path.join(dir, file))
                )

    else:
        _already_checked_cache.add(fp)
        module_names = cdev_parser.parse_file_for_dependencies(fp)

    return list(module_names)


def _load_standard_library_information(version=&#34;3_6&#34;):
    FILE_LOC = os.path.join(
        os.path.dirname(__file__), &#34;standard_library_names&#34;, f&#34;python_{version}&#34;
    )

    if not os.path.isfile(FILE_LOC):
        # TODO throw error
        raise FileNotFoundError

    with open(FILE_LOC) as fh:
        return set(fh.read().splitlines())


def _load_aws_packages(version=&#34;3_6&#34;):
    return set([&#34;boto3&#34;, &#34;botocore&#34;])


def _load_mod_to_prj():
    return MOD_NAME_TO_PRJ_OBJ</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="core.utils.fs_manager.package_mananger.get_top_level_module_info"><code class="name flex">
<span>def <span class="ident">get_top_level_module_info</span></span>(<span>modules: List[str], start_location: pydantic.types.FilePath) ‑> Dict[str, <a class="" title="core.utils.fs_manager.utils.ModulePackagingInfo" href="utils.html#core.utils.fs_manager.utils.ModulePackagingInfo">ModulePackagingInfo</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Create a sorted dictionary of all the module information needed for the used modules in a handler.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>modules</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>Module names used to by a handler</dd>
<dt><strong><code>start_location</code></strong> :&ensp;<code>Filepath</code></dt>
<dd>The location of the original file to help dereference relative modules</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>module_infos (SortedDict[str, ModulePackagingInfo]): Dict (Sorted by module name) of the module information
objects that will be used to package the module with the handler</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_top_level_module_info(
    modules: List[str], start_location: FilePath
) -&gt; Dict[str, ModulePackagingInfo]:
    &#34;&#34;&#34;
    Create a sorted dictionary of all the module information needed for the used modules in a handler.

    Args:
        modules (List[str]): Module names used to by a handler
        start_location (Filepath): The location of the original file to help dereference relative modules

    Returns:
        module_infos (SortedDict[str, ModulePackagingInfo]): Dict (Sorted by module name) of the module information
        objects that will be used to package the module with the handler
    &#34;&#34;&#34;
    all_packages = {}

    _clear_already_checked_cache(start_location)

    for module_name in modules:
        all_packages[module_name] = _get_module_info(module_name, start_location)

    return SortedDict(all_packages)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<img class='logo-img' src="https://s3.amazonaws.com/cdevframework.io/images/CoreLogo.svg" alt="site">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a class="sidebar" title="core.utils.fs_manager" href="index.html">core.utils.fs_manager</a></code></li>
</ul>
</li>
<li><h3><a class='nav-header' href="#header-functions">Functions</a></h3>
<ul >
<li><code><a class="sidebar" title="core.utils.fs_manager.package_mananger.get_top_level_module_info" href="#core.utils.fs_manager.package_mananger.get_top_level_module_info">get_top_level_module_info</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>