<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>core.utils.fs_manager.package_mananger API documentation</title>
<meta name="description" content="Module that contains functionality to manage the understanding of packages within this `Workspace`" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em;background:#EEE}#content{padding:20px}#sidebar{padding:30px;overflow:hidden;background:#07085d}#sidebar > *:last-child{margin-bottom:2cm}#sidebar::-webkit-scrollbar{width:8px}#sidebar::-webkit-scrollbar-track{border-radius:10px;background:#f1f1f100}#sidebar::-webkit-scrollbar-thumb{border-radius:10px;background:linear-gradient( 37deg,rgb(247,70,58) 1%,rgb(180,62,121) 80% )}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}a.sidebar{color:white;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#f7463a}a.nav-header{color:white}img.logo-img{display:block;margin-left:auto;margin-right:auto;width:25%}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#e0e0e0;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{height:100vh;overflow:auto;position:sticky;top:0;background:#07085d}#content{width:70%;max-width:200ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<!--<link rel="stylesheet"
href='https://cdevwebsitestaging.s3.amazonaws.com/bootstrap/css/bootstrap.min.css'>-->
<script href='/bootstrap/css/bootstrap.js'></script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>core.utils.fs_manager.package_mananger</code></h1>
</header>
<section id="section-intro">
<p>Module that contains functionality to manage the understanding of packages within this <code>Workspace</code></p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Module that contains functionality to manage the understanding of packages within this `Workspace`
&#34;&#34;&#34;

import os
from pathlib import Path
import pkg_resources
from pydantic.types import DirectoryPath, FilePath
from sortedcontainers.sorteddict import SortedDict
import sys
from typing import List, Set, Dict, Tuple, Union, Optional

from serverless_parser import parser as cdev_parser

from . import docker_package_builder
from .utils import PackageTypes, ModulePackagingInfo, environment_to_architecture_suffix, Architecture

from core.utils.platforms import lambda_python_environment, get_current_closest_platform
from core.utils.logger import log

# Keep cache of already seen package names
PACKAGE_CACHE = {}

# There isn&#39;t a great runtime way of identifying python standard libraries (non C builtin libraries packaged with python).
# So I scraped the information from the python documentation website using the ./scripts/list-python-builtins
STANDARD_LIBRARY_FILES = [&#34;3_7&#34;, &#34;3_8&#34;, &#34;3_9&#34;]

# Build a dict of pkg name to pip package obj so you don&#39;t have to loop over all the packages when doing a look up
# We need to include both a the project name and &#39;toplevel&#39; name. This is because a project can have a python unsafe name
# so it is allowed to have a different name that is used when importing the package in an actual python file. Both need to
# be include because, when the package is reference directly in a file it will have the top name, but when it is referenced
# as the dependency of another project it will be a the project name.
MOD_NAME_TO_PRJ_OBJ: Dict[str, pkg_resources.Distribution] = {}

PRJ_NAME_TO_TOP_LEVEL_MODULES: Dict[str, List[str]] = {}

PLATFORM_DEPENDENT_PROJECTS = set()

_already_checked_cache = set()

download_package_location = None

target_platform = get_current_closest_platform()
CURRENT_PLATFORM = get_current_closest_platform()

#_current_working_dir = CDEV_SETTINGS.get(&#34;CURRENT_PARSING_DIR&#34;)
# TODO: Make this a setting
_current_working_dir = os.getcwd()

environment_to_python_std = {
    lambda_python_environment.py37: &#34;3_7&#34;,
    lambda_python_environment.py38_x86_64: &#34;3_8&#34;,
    lambda_python_environment.py38_arm64: &#34;3_8&#34;,
    lambda_python_environment.py39_x86_64: &#34;3_9&#34;,
    lambda_python_environment.py39_arm64: &#34;3_9&#34;,
    lambda_python_environment.py3_x86_64: &#34;3_9&#34;,
    lambda_python_environment.py3_arm64: &#34;3_9&#34;,
}


def _is_platform_compatible(tags: List[str]) -&gt; bool:
    # https://packaging.python.org/specifications/platform-compatibility-tags/
    # PEP 600
    interpreter_tag = tags[0]
    platform_tag = tags[-1]

    if not (interpreter_tag[:2] == &#34;py&#34; or interpreter_tag[:2] == &#34;cp&#34;):
        # Not a cpython or generic python package
        raise Exception

    if platform_tag == &#34;any&#34;:
        return True

    if &#34;win32&#34; in platform_tag:
        return False

    elif &#34;macosx&#34; in platform_tag:
        return False

    else:
        #Linux specific package
        return False


for project_obj in pkg_resources.working_set:
    # We need to compute some information about the available modules in the current environment. This will help to provide information about
    # the modules when handlers reference them.

    # Compute:
    # MOD_NAME_TO_PRJ_OBJ -&gt; Dict from the module name to the project object that contains the metadata about the project the module is from
    # PRJ_NAME_TO_TOP_LEVEL_MODULES -&gt; Dict from the project name to all of its top level modules which are used when including the project as a dependency
    # INCOMPATIBLE_PROJECTS -&gt; Projects that are not platform agnostic and would therefore need to be redownloaded for the correct deployment architecture 

    # For information on this object check
    # https://setuptools.pypa.io/en/latest/pkg_resources.html#distribution-objects
    # Distribution Object

    # find the dist info directory that will contain metadata about the package
    dist_dir_location = os.path.join(
        project_obj.location,
        f&#34;{project_obj.project_name.replace(&#39;-&#39;, &#39;_&#39;)}-{project_obj.parsed_version}.dist-info&#34;,
    )
    toplevel_file_location = os.path.join(dist_dir_location, &#34;top_level.txt&#34;)
    wheel_info = os.path.join(dist_dir_location, &#34;WHEEL&#34;)

    if not os.path.isdir(dist_dir_location):
        continue

    if not os.path.isfile(toplevel_file_location):
        # If not top level file is present, then assume the only top level module available is the project name
        MOD_NAME_TO_PRJ_OBJ[project_obj.project_name] = project_obj
        PRJ_NAME_TO_TOP_LEVEL_MODULES[project_obj.project_name] = [
            project_obj.project_name
        ]
        continue

    with open(toplevel_file_location) as fh:
        top_level_mod_names = fh.readlines()

        for top_level_mod_name in top_level_mod_names:
            MOD_NAME_TO_PRJ_OBJ[top_level_mod_name.strip()] = project_obj

        potential_modules = [x.strip() for x in top_level_mod_names]
        actual_modules = []
        for potential_module in potential_modules:
            # The module could be either a folder (normal case) or a single python file (ex: &#39;six&#39; package)
            # If it can not be found as either than there is an issue
            potential_dir = os.path.join(project_obj.location, potential_module)
            potential_file = os.path.join(
                project_obj.location, potential_module + &#34;.py&#34;
            )

            if not os.path.isdir(potential_dir) and not os.path.isfile(potential_file):
                # print(f&#34;Could not find module {potential_module} at {dist_dir_location}&#34;)
                continue

            actual_modules.append(potential_module)

        PRJ_NAME_TO_TOP_LEVEL_MODULES[project_obj.project_name] = actual_modules

    with open(wheel_info) as fh:
        lines = fh.readlines()

        # https://www.python.org/dev/peps/pep-0425/
        # if it is not pure it should only have one tag
        # We are going ot check the tags of the package to make sure it is compatible with the target deployment platform
        tags = (
            [x.split(&#34;:&#34;)[1] for x in lines if x.split(&#34;:&#34;)[0] == &#34;Tag&#34;][0]
            .strip()
            .split(&#34;-&#34;)
        )

        if not _is_platform_compatible(tags):
            PLATFORM_DEPENDENT_PROJECTS.add(project_obj.project_name)

######################
##### Helper Functions
######################

def _load_aws_packages(version=&#34;3_6&#34;):
    &#34;&#34;&#34;Returns the given built in third party packages for a given platform

    Args:
        version (str, optional): [description]. Defaults to &#34;3_6&#34;.

    Returns:
        set[str]: modules
    &#34;&#34;&#34;
    return set([&#34;boto3&#34;, &#34;botocore&#34;])


def _load_mod_to_prj():
    return MOD_NAME_TO_PRJ_OBJ


def _load_standard_library_information(version=&#34;3_6&#34;):
    FILE_LOC = os.path.join(
        os.path.dirname(__file__), &#34;standard_library_names&#34;, f&#34;python_{version}&#34;
    )

    if not os.path.isfile(FILE_LOC):
        # TODO throw error
        raise FileNotFoundError

    with open(FILE_LOC) as fh:
        return set(fh.read().splitlines())

def _clear_already_checked_cache(starting_location: str):
    # Add the starting file of the recursive calls
    global _already_checked_cache

    _already_checked_cache = set()

    _already_checked_cache.add(starting_location)

##########################
##### Main Entry Point
##########################

def get_top_level_module_info(
    modules: List[str], start_location: FilePath, target_platform_param: lambda_python_environment, download_package_location_param: DirectoryPath = None,
) -&gt; Dict[str, ModulePackagingInfo]:
    &#34;&#34;&#34;Given a set of modules, find the information needed to package those modules. 

    Args:
        modules (List[str]): Module names used to by a handler
        target_platform_param (lambda_python_environment): environment the function will be deployed on, which can affect what version of
        a 3rd party module is used.
        download_package_location_param (DirectoryPath): Base Directory that any downloaded package from Docker will be stored.

    Returns:
        module_infos (SortedDict[str, ModulePackagingInfo]): Dict (Sorted by module name) of the module information
        objects


    A handler file will have a set top level modules that are defined at the top of the file. We need to determine the module information
    about these and then return them in a way that allows them to be packaged efficiently. 


    &#34;&#34;&#34;
    
    # Set the global value for the recursive function to use
    global download_package_location
    download_package_location = download_package_location_param

    global target_platform
    target_platform = target_platform_param

    log.debug(&#39;Getting Module Packaging Info for modules %s for target platform %s&#39;, modules, target_platform)
    
    all_packages = {}

    # we want to keep a cache of files we have already checked to speed up the process
    # clear this cache between iterations to make sure no files have changed
    _clear_already_checked_cache(start_location)

    for module_name in modules:
        all_packages[module_name] = _get_module_info(module_name, start_location)

    return SortedDict(all_packages)


def _get_module_info(
    module_name: str, original_file_location: str
) -&gt; ModulePackagingInfo:
    &#34;&#34;&#34;Create the information needed to package this dependency with a parsed function. 
    
    Args:
        module_name (str): The module name to look up. It can also be a relative name (begins with &#39;.&#39;)
        original_file_location (str): Since the module name can be a relative import it needs to have the location of the
        starting location to help resolve the reference

    Returns
        info (ModulePackagingInfo): information for the packages to package

    We use the recursive method because we must compute the package information for the dependencies of this dependency. 
   
    &#34;&#34;&#34;
    log.debug(&#39;Top Getting Module Packaging Info for module %s&#39;, module_name)
    # Note the package cache is implemented at the recursive level so that recursive calls can benefit from the cache also
    info = _recursive_create_module_package_info(module_name, original_file_location)

    log.debug(&#39;Top Recieve Module Packaging Info %s for module %s&#39;, info, module_name)

    return info





def _recursive_create_module_package_info(
    module_name: str, original_file_location: str
) -&gt; ModulePackagingInfo:
    &#34;&#34;&#34;Recursively create a module information object by finding out what type of module this is, and then recursively creating
    any dependant modules.

    Args:
        module_name (str): This is the top level module name used by the handler (can be a relative module)
        original_file_location: Location to use as start point if a local module is given

    Returns:
        module_info (ModulePackagingInfo): Information object for the given module

    &#34;&#34;&#34;

    global download_package_location
    global target_platform

    if (module_name, original_file_location) in PACKAGE_CACHE:
        # Look in the cache if there is already information about this module to speed up the process
        log.debug(&#39;Package CACHE HIT for  (%s,%s)&#39;, module_name, original_file_location)
        return PACKAGE_CACHE.get((module_name, original_file_location))

    if (
        not module_name in sys.modules
        and not module_name in MOD_NAME_TO_PRJ_OBJ
        and not module_name[0] == &#34;.&#34;
    ):
        # The module name is not in the available system modules and also not a relative module
        raise Exception(f&#34;Bad module name {module_name}; Not a sys module, relatively referenced package, or pip installed package&#34;)

    else:
        standard_lib_info = _load_standard_library_information(environment_to_python_std.get(target_platform))
        aws_packages = _load_aws_packages(environment_to_python_std.get(target_platform))
        pip_packages = _load_mod_to_prj()

        if module_name in standard_lib_info:
            # Module is from the standard library
            log.debug(&#39;Standard Library: %s&#39;, module_name)
            rv = ModulePackagingInfo(
                **{
                    &#34;module_name&#34;: module_name,
                    &#34;type&#34;: PackageTypes.STANDARDLIB,
                    &#34;version_id&#34;: None,
                    &#34;fp&#34;: None,
                }
            )

        elif module_name in aws_packages:
            # Module is part of the default libraries available in the aws lambda python environment
            log.debug(&#39;Library included with runtime environment: %s&#39;, module_name)
            rv = ModulePackagingInfo(
                **{
                    &#34;module_name&#34;: module_name,
                    &#34;type&#34;: PackageTypes.AWSINCLUDED,
                    &#34;version_id&#34;: None,
                    &#34;fp&#34;: None,
                }
            )

        elif module_name in pip_packages:
            # Module was installed with a package manager and therefor contains additional metadata that can be used to find the dependencies
            log.debug(&#39;Pip package: %s&#39;, module_name)
            tmp_distribution_obj = pip_packages.get(module_name)

            project_name = tmp_distribution_obj.project_name

            module_arch = Architecture.ANY

            if project_name in PLATFORM_DEPENDENT_PROJECTS:
                log.debug(&#39;Pip package %s is not a universal package&#39;, module_name)
                # Some of the projects that can be installed are platform dependant and the users environment might not match the aws lambda
                # environment. So, we need to use docker to pull the compatible version of the library then use that in the final archive
                
                if CURRENT_PLATFORM and (CURRENT_PLATFORM == target_platform):
                    # IF the current platform exists and is the same as the target platform no need to download a new version
                    module_arch = environment_to_architecture_suffix.get(CURRENT_PLATFORM)
                    log.debug(&#39;Target Platform matches Current Platform (%s) for pkg %s &#39;, target_platform, module_name)

                elif download_package_location:
                    # Else there needs to be a provided download location
                    if docker_package_builder.docker_available():
                        log.debug(&#39;User Docker to pull pkg %s &#39;, module_name)

                        # Note that the download package function uses a cache so it will only actually pull the first time the user wants to
                        # package this function.
                        rv = docker_package_builder.download_package_and_create_moduleinfo(
                            tmp_distribution_obj,
                            target_platform,
                            module_name,
                            download_package_location
                        )
                        PACKAGE_CACHE[(module_name, original_file_location)] = rv
                        return rv

                    else:
                        raise Exception(&#34;Trying to target an architecture with a dependant package but Docker is not available&#34;)

                else:
                    raise Exception(&#34;Trying to target an architecture with a dependant package but have Docker is not allowed&#34;)

            # The package could be either a folder (normal case) or a single python file (ex: &#39;six&#39; package)
            # If it can not be found as either than there is an issue
            potential_dir = os.path.join(
                pip_packages.get(module_name).location, module_name
            )
            potential_file = os.path.join(
                pip_packages.get(module_name).location, module_name + &#34;.py&#34;
            )

            if os.path.isdir(potential_dir):
                tmp_fp = potential_dir
            elif os.path.isfile(potential_file):
                tmp_fp = potential_file
            else:
                raise Exception

            log.debug(&#34;Final fp for %s -&gt; %s&#34;, module_name, tmp_fp)

            # Find the dependent modules for this project (distribution obj)
            (
                tmp_dependencies_flat,
                tmp_dependencies_tree,
            ) = _recursive_check_for_dependencies_project(tmp_distribution_obj)


            log.debug(&#34;Flat dependencies for %s -&gt; %s&#34;, module_name, tmp_dependencies_flat)
            log.debug(&#34;Tree dependencies for %s -&gt; %s&#34;, module_name, tmp_dependencies_tree)
            
            rv = ModulePackagingInfo(
                **{
                    &#34;module_name&#34;: module_name,
                    &#34;type&#34;: PackageTypes.PIP,
                    &#34;arch&#34;: module_arch,
                    &#34;version_id&#34;: tmp_distribution_obj.version,
                    &#34;fp&#34;: tmp_fp,
                    &#34;flat&#34;: tmp_dependencies_flat,
                    &#34;tree&#34;: tmp_dependencies_tree,
                }
            )

        else:
            # Since the module is not in the PIP, platform builtins, or std lib
            # It should be treated as a local package
            mod = sys.modules.get(module_name)
            if mod:
                if not mod.__file__:
                    # if the module __file__ is not present than it is a builtin module to the interpreter
                    tmp_type = PackageTypes.BUILTIN
                    tmp_fp = None
                    tmp_version = None
                else:
                    # this is a local package that was not imported using a relative path
                    tmp_type = PackageTypes.LOCALPACKAGE
                    tmp_version = None

                    if mod.__file__.split(&#34;/&#34;)[-1] == &#34;__init__.py&#34;:
                        tmp_fp = os.path.dirname(mod.__file__)
                    else:
                        tmp_fp = mod.__file__
                    # TODO: Maybe support this in the future
                    log.debug(&#34;Local absolute reference for module %s&#34;, module_name)
                    raise Exception(&#34;Referencing local package using absolute import statement. Change it to a relative import to work with Cdev.&#34;)
            elif module_name[0] == &#34;.&#34;:
                # IF the module name started with a &#39;.&#39; then it is a relative import
                
                tmp_type = PackageTypes.LOCALPACKAGE
                original_path = Path(original_file_location)

                tmp_version = None

                tmp_module_name = module_name

                levels = 0
                # loop to compute how many layers up this relative import is by popping off the &#39;.&#39; char
                # until it reaches a different char
                while tmp_module_name[0] == &#34;.&#34;:
                    tmp_module_name, next_char = tmp_module_name[1:], tmp_module_name[0]

                    if next_char == &#34;.&#34;:
                        levels = levels + 1
                    else:
                        break
                
                log.debug(&#34;%s if %s levels up from handler&#34;, module_name, levels)

                # go up the amount of levels need to get to the top of the search path
                relative_base_dir = original_path.parents[levels - 1]

                # since we popped off the leading &#39;.&#39; chars, the remaining portion is the path to search down from the top
                tmp_pkg_path_parts = tmp_module_name.split(&#34;.&#34;)

                # Again the module can either be a single file or a directory containing other files
                tmp_potential_file = os.path.join(
                    relative_base_dir,
                    &#34;/&#34;.join(tmp_pkg_path_parts[:-1]),
                    tmp_pkg_path_parts[-1] + &#34;.py&#34;,
                )
                tmp_potential_dir = os.path.join(
                    relative_base_dir, &#34;/&#34;.join(tmp_pkg_path_parts)
                )

                if os.path.isfile(tmp_potential_file):
                    tmp_fp = tmp_potential_file
                    
                elif os.path.isdir(tmp_potential_dir):
                    tmp_fp = tmp_potential_dir
                else:
                    raise Exception

                log.debug(&#34;Final relative file location (%s) from workspace to %s&#34;, tmp_fp, module_name)
                

            else:
                raise Exception(f&#34;Unmanageable module name for local module {module_name}&#34;)

            # Since this is a local package, it does not contain any extra metadata. This means the only way to find the dependencies is to
            # parse each python file in the needed module and look at its imports :/
            (
                dependencies_flat,
                dependencies_tree,
            ) = _recursive_check_for_dependencies_package(tmp_fp)
            log.debug(&#34;Flat dependencies for %s -&gt; %s&#34;, module_name, dependencies_flat)
            log.debug(&#34;Tree dependencies for %s -&gt; %s&#34;, module_name, dependencies_tree)

            rv = ModulePackagingInfo(
                **{
                    &#34;module_name&#34;: module_name,
                    &#34;type&#34;: tmp_type,
                    &#34;version_id&#34;: tmp_version,
                    &#34;fp&#34;: tmp_fp,
                    &#34;flat&#34;: dependencies_flat,
                    &#34;tree&#34;: dependencies_tree,
                }
            )

        PACKAGE_CACHE[(module_name, original_file_location)] = rv
        log.debug(&#34;Add to cache (%s,%s) =&gt; %s&#34;, module_name, original_file_location, rv)
        return rv


def _recursive_check_for_dependencies_project(
    project_distribution_obj: pkg_resources.Distribution,
) -&gt; Tuple[List[ModulePackagingInfo], List[ModulePackagingInfo]]:
    &#34;&#34;&#34;
    Create the ModulePackagingInfo objects for all dependencies of this project. By calling the &#39;_recursive_create_module_package_info&#39; to create the
    ModulePackagingInfo objects, it creates a recursive stack that eventually leads to tmp_flat being a list of ALL needed dependencies and the tmp_tree
    to be the first level in the dependency tree for this project.

    Args:
        project_distribution_obj (pkg_resources.Distribution): object from pkg_resources that contains metadata on this package

    Returns:
        flat (List[ModulePackagingInfo]): List of ALL needed dependencies
        tree (List[ModulePackagingInfo]): First level of a dependency tree for this project
    &#34;&#34;&#34;
    tmp_flat = set()
    tmp_tree = set()

    for project_obj in project_distribution_obj.requires():

        if project_obj.project_name in PRJ_NAME_TO_TOP_LEVEL_MODULES:
            project_name = project_obj.project_name

        # Note that pip packages should list their dependencies as the project name, but some use the top level module name that
        # can be slightly different than the project name.
        # Example awswrangler (2.12.1) lists &#39;Requires-Dist: pymysql (&gt;=0.9.0,&lt;1.1.0)&#39; but the actual package name is &#39;PyMySQL&#39;
        # .....python packaging sucks
        elif project_obj.project_name in MOD_NAME_TO_PRJ_OBJ:
            project_name = MOD_NAME_TO_PRJ_OBJ.get(
                project_obj.project_name
            ).project_name
        else:
            raise Exception

        top_level_modules = PRJ_NAME_TO_TOP_LEVEL_MODULES.get(project_name)

        for req in top_level_modules:

            tmp_dep = _recursive_create_module_package_info(req, None)
            tmp_flat.add(tmp_dep)
            tmp_tree.add(tmp_dep)

            if tmp_dep.flat:
                tmp_flat = tmp_flat.union(set(tmp_dep.flat))

    return tmp_flat, tmp_tree


def _recursive_check_for_dependencies_package(
    fp: Union[FilePath, DirectoryPath]
) -&gt; Tuple[List[ModulePackagingInfo], List[ModulePackagingInfo]]:
    &#34;&#34;&#34;Create the ModulePackagingInfo objects for all dependencies of a local module. 
    
    By calling the &#39;_recursive_create_module_package_info&#39; to create the ModulePackagingInfo objects,
    it creates a recursive stack that eventually leads to tmp_flat being a list of ALL needed dependencies 
    and the tmp_tree to be the first level in the dependency tree for this project.

    Args:
        fp (Union[FilePath, DirectoryPath]): object from pkg_resources that contains metadata on this package

    Returns:
        flat (List[ModulePackagingInfo]): List of ALL needed dependencies
        tree (List[ModulePackagingInfo]): First level of a dependency tree for this project
    &#34;&#34;&#34;
    tmp_flat = set()
    tmp_tree = set()

    required_items = _get_local_package_dependencies(fp)

    for req in required_items:
        starting_location = fp if not req[1] else req[1]

        tmp_dep = _recursive_create_module_package_info(req[0], starting_location)

        tmp_flat.add(tmp_dep)
        tmp_tree.add(tmp_dep)

        if tmp_dep.flat:
            tmp_flat = tmp_flat.union(set(tmp_dep.flat))

    return list(tmp_flat), tmp_tree


def _get_local_package_dependencies(
    fp: Union[FilePath, DirectoryPath]
) -&gt; List[Tuple[str, Optional[str]]]:
    &#34;&#34;&#34;
    Get the local dependencies for a given local module by searching through the file(s) that make up the module and looking
    for import statements.

    Args:
        fp (Union[FilePath, DirectoryPath]): the location of the module in question

    Returns:
        dependencies (List[Tuple[str,str]]): List of dependant module names and an optional filepath if the module is a relative module


    Uses the Serverless Parser library to find all the imports in a given file.
    &#34;&#34;&#34;
    global _current_working_dir

    if not _current_working_dir:
        # This setting should be set
        raise Exception

    # Since we are just reading the files not importing them. We do not have a guarantee to not cause a circular dependency
    # Therefore, we preload all the files we are going to check before checking them, and add that to a cache to check against
    # If a file is already in the cache, it means it has/or will be accounted for.

    if fp in _already_checked_cache:
        # We have already included this file so skip it
        return []

    # Local Module can be either directory or single file
    if os.path.isdir(fp):
        module_names = set()

        for dir, _, files in os.walk(fp):
            if dir in _already_checked_cache:
                continue

            # Load the directory (and subdirectories)
            _already_checked_cache.add(dir)

            for file in files:
                if not file[-3:] == &#34;.py&#34;:
                    continue

                # Load the files
                if os.path.join(dir, file) in _already_checked_cache:
                    continue

                _already_checked_cache.add(os.path.join(dir, file))

                module_names = module_names.union(
                    cdev_parser.parse_file_for_dependencies(os.path.join(dir, file))
                )
                log.debug(&#34;Found dependent modules %s for %s&#34;, module_names, os.path.join(dir, file))

    else:
        _already_checked_cache.add(fp)
        module_names = cdev_parser.parse_file_for_dependencies(fp)
        
    log.debug(&#34;Found dependent modules %s for %s&#34;, module_names, fp)

    return list(module_names)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="core.utils.fs_manager.package_mananger.get_top_level_module_info"><code class="name flex">
<span>def <span class="ident">get_top_level_module_info</span></span>(<span>modules: List[str], start_location: pydantic.types.FilePath, target_platform_param: <a class="" title="core.utils.platforms.lambda_python_environment" href="../platforms.html#core.utils.platforms.lambda_python_environment">lambda_python_environment</a>, download_package_location_param: pydantic.types.DirectoryPath = None) ‑> Dict[str, <a class="" title="core.utils.fs_manager.utils.ModulePackagingInfo" href="utils.html#core.utils.fs_manager.utils.ModulePackagingInfo">ModulePackagingInfo</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Given a set of modules, find the information needed to package those modules. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>modules</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>Module names used to by a handler</dd>
<dt><strong><code>target_platform_param</code></strong> :&ensp;<code>lambda_python_environment</code></dt>
<dd>environment the function will be deployed on, which can affect what version of</dd>
<dt>a 3rd party module is used.</dt>
<dt><strong><code>download_package_location_param</code></strong> :&ensp;<code>DirectoryPath</code></dt>
<dd>Base Directory that any downloaded package from Docker will be stored.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>module_infos (SortedDict[str, ModulePackagingInfo]): Dict (Sorted by module name) of the module information
objects
A handler file will have a set top level modules that are defined at the top of the file. We need to determine the module information
about these and then return them in a way that allows them to be packaged efficiently.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_top_level_module_info(
    modules: List[str], start_location: FilePath, target_platform_param: lambda_python_environment, download_package_location_param: DirectoryPath = None,
) -&gt; Dict[str, ModulePackagingInfo]:
    &#34;&#34;&#34;Given a set of modules, find the information needed to package those modules. 

    Args:
        modules (List[str]): Module names used to by a handler
        target_platform_param (lambda_python_environment): environment the function will be deployed on, which can affect what version of
        a 3rd party module is used.
        download_package_location_param (DirectoryPath): Base Directory that any downloaded package from Docker will be stored.

    Returns:
        module_infos (SortedDict[str, ModulePackagingInfo]): Dict (Sorted by module name) of the module information
        objects


    A handler file will have a set top level modules that are defined at the top of the file. We need to determine the module information
    about these and then return them in a way that allows them to be packaged efficiently. 


    &#34;&#34;&#34;
    
    # Set the global value for the recursive function to use
    global download_package_location
    download_package_location = download_package_location_param

    global target_platform
    target_platform = target_platform_param

    log.debug(&#39;Getting Module Packaging Info for modules %s for target platform %s&#39;, modules, target_platform)
    
    all_packages = {}

    # we want to keep a cache of files we have already checked to speed up the process
    # clear this cache between iterations to make sure no files have changed
    _clear_already_checked_cache(start_location)

    for module_name in modules:
        all_packages[module_name] = _get_module_info(module_name, start_location)

    return SortedDict(all_packages)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<img class='logo-img' src="https://s3.amazonaws.com/cdevframework.io/images/CoreLogo.svg" alt="site">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a class="sidebar" title="core.utils.fs_manager" href="index.html">core.utils.fs_manager</a></code></li>
</ul>
</li>
<li><h3><a class='nav-header' href="#header-functions">Functions</a></h3>
<ul >
<li><code><a class="sidebar" title="core.utils.fs_manager.package_mananger.get_top_level_module_info" href="#core.utils.fs_manager.package_mananger.get_top_level_module_info">get_top_level_module_info</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>